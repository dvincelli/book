# Optimisation

(The basic idea of this chapter: give a general introduction of this topic regardless of Owl; when Owl has corresponding function, we provide a simple example.)

## Introduction 

Mathematical optimization deals with the problem of finding numerically minimums, maximums or zeros of a function. In this context, the function is called cost function, or objective function.

REFERENCE: Practical Methods of Optimization by Fletcher.

Basic theories.

## Scalar Functions 

## Multivariate Function


### Gradient Descent Method


### Conjugate Gradient Method


### Newton Method


### L-BFGS

### Other Algorithms

## Root Finding

## Optimisation in Practice: Training Neural Network

Adagrad etc in action; where do they fit in the previous theory?


NOTE: perhaps also add in global optimisation section. Linear Programming?...

Also, I need to at least explain what is hessian/jacobian etc. in this chapter.
