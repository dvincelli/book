<html style="" lang="en" class="js flexbox fontface"><head><meta charset="utf-8"><meta content="width=device-width, initial-scale=1.0" name="viewport"><title>Ordinary Differential Equations - OCaml Scientific Computing</title><link href="css/app.css" rel="stylesheet"><link href="css/prism.css" rel="stylesheet"><script src="js/min/modernizr-min.js"></script><script src="js/prism.js"></script><script src="https://use.typekit.net/gfj8wez.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>try{Typekit.load();}catch(e){}</script></head><body><div class="title-bar"><div class="title"><h1>OCaml Scientific Computing</h1><h5>1<sup>st</sup> Edition (in progress)</h5><nav><a href="index.html">Home</a><a href="toc.html">Table of Contents</a><a href="faqs.html">FAQs</a><a href="install.html">Install</a><a href="https://ocaml.xyz/package/">API Docs</a></nav></div></div><div class="wrap"><div class="left-column"><a class="to-chapter" href="toc.html"><small>Back</small><h5>Table of Contents</h5></a></div><article class="main-body"><section class="level1" id="ordinary-differential-equations">
<h1>Ordinary Differential Equations</h1>
<section class="level2" id="what-is-an-ode">
<h2>What Is An ODE</h2>
<p>A <em>differential equation</em> is an equation that contains a function and one or more of its derivatives. It is studied ever since the invention of calculus, driven by the applications in mechanics, astronomy, and geometry. Currently it has become a important branch of mathematics study and its application is widely extended to biology, engineering, economics, and much more fields.</p>
<p>In a differential equation, if the function and its derivatives are about only one variable, we call it an <em>Ordinary Differential Equation</em>(ODE). It is often used to model one-dimensional dynamical systems. Otherwise it is an <em>Partial Differential Equation</em>(PDE). In this chapter we focus on the former one.</p>
<p>Generally, a ODE can be expressed as:</p>
<p><span id="eq:diffequation:ode-def"><span class="math display">\[ F(x, y^{'}, y^{''}, \ldots, y^{(n)}) = 0.\qquad(1)\]</span></span></p>
<p>The differential equations model dynamic systems, and the initial status of the system is often known. That is called <em>initial values</em>. They can be represented as:</p>
<p><span id="eq:diffequation:init"><span class="math display">\[y|_{x=x_0} = y_0, y^{'}|_{x=x_1} = y_1, \ldots ,\qquad(2)\]</span></span></p>
<p>where the <span class="math inline">\(y_0\)</span>, <span class="math inline">\(y_1\)</span>, etc. are known. The highest order of derivatives that are used in eq.&nbsp;1 is the <em>order</em> of this differential equation. A first-order differential equation can be generally expressed as: <span class="math inline">\(\frac{dy}{dx}=f(x,y)\)</span>, where <span class="math inline">\(f\)</span> is any function that contains <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>Solving eq.&nbsp;1 that fits given initial values as in eq.&nbsp;2 is called the <em>initial value problem</em>. Solving this kind of problems is the main target of many numerical ODE solvers.</p>
<section class="level3" id="exact-solutions">
<h3>Exact Solutions</h3>
<p>Solving a differential equation is often complex, but we do not how to solve part of them. Before looking at the the solvers to a random ODEs, let’s turn to the math first and look at some ODE forms that we already have analytical close-form solution.</p>
<p><strong>Separable equations</strong>:</p>
<p><span class="math display">\[P(y)\frac{dy}{dx} + Q(x) = 0,\]</span></p>
<p>and it’s close form solution is:</p>
<p><span class="math display">\[\int^{y}P(y)dy + \int^{x}Q(x)dx = C\]</span>.</p>
<p><strong>Linear first-order equations</strong>:</p>
<p><span class="math display">\[\frac{dy}{dx} + P(x)y = Q(x)\]</span></p>
<p>It’s solution is:</p>
<p>EQUATION</p>
<p>Solving ODE analytically is not the focus of solvers. REFER to classical math book (reference required) or full course for more detail.</p>
</section>
</section>
<section class="level2" id="solving-an-ode-numerically">
<h2>Solving An ODE Numerically</h2>
<p>This chapter should be built around examples:</p>
<ul>
<li>make very clear what kind of problems we can solve at the beginning. Even MATLAB can only solve a certain kinds of ODEs, and that’s no problem at all;</li>
<li>a lot of examples</li>
<li>explain how these solvers work</li>
<li>finally, real problems: compound interest, chemical reactions etc. and solve them. From textbooks; compare with analytical solutions.</li>
</ul>
<section class="level3" id="basic-methods">
<h3>Basic Methods</h3>
<p>Let’s start with an example:</p>
<p><span id="eq:diffequation:example01"><span class="math display">\[y' = 2xy + x,\qquad(3)\]</span></span></p>
<p>where the initial value is <span class="math inline">\(y(0) = 0\)</span>. Without going deep into the whole math calculation process (hint: it’s a separable first-order ODE), we give its analytical close-form solution:</p>
<p><span id="eq:diffequation:example01_solution"><span class="math display">\[y = 0.5(\exp{x^2} - 1).\qquad(4)\]</span></span></p>
<p>Now, pretending we don’t know the solution in eq.&nbsp;4, and we want to answer the question: what is <span class="math inline">\(y\)</span>’s value when <span class="math inline">\(x = 1\)</span> (or any other value)? How can we solve it numerically?</p>
<p>Meet the <em>Euler Method</em>, a first-order numerical procedure to solve initial value problems. This method proposes to approximate the function <span class="math inline">\(y\)</span> using a sequence of iterative steps:</p>
<p><span class="math display">\[ y_{n+1} = y_n + \Delta~f(x_n, y_n),\]</span></p>
<p>where <span class="math inline">\(\Delta\)</span> is a certain step size. This method is really easy to be implemented in OCaml, as shown below.</p>
<div class="highlight">
<pre><code class="language-ocaml">let x = ref 0.
let y = ref 0.
let target = 1.
let step = 0.001
let f x y = 2. *. x *. y +. x

let _ = 
  while !x &lt;= target do 
    y := !y +. step *. (f !x !y);
    x := !x +. step
  done</code></pre>
</div>
<p>In this case, we know that the analytical solution at <span class="math inline">\(x=1\)</span> is <span class="math inline">\(0.5(\exp{1^2} - 1\)</span>:</p>
<div class="highlight">
<pre data-filter-output=">" data-prompt="#" class="command-line"><code class="language-ocaml">(Owl_const.e -. 1.)/. 2.;;
&gt;- : float = 0.859140914229522545
</code></pre>
</div>
<p>and the solution given by the previous numerical code is about <code>0.8591862</code>, which is pretty close to the true answer.</p>
<p>However, this method is as easy as it is unsuitable to be used in practical applications. One reason is that this method is not very accurate, despite that it works well in our example here. We will show this point soon. Also, it is not very stable, nor does it provide error estimate.</p>
<p>Therefore, we can modify the Euler’s method to use a “midpoint” in stepping, hoping to curb the error in the update process:</p>
<p><span class="math display">\[ s_1 = f(x_n, y_n),\]</span> <span id="eq:diffequation:rk2"><span class="math display">\[ s_2 = f(x_n + \Delta~/2, y_n + s_1~\Delta~/2),\qquad(5)\]</span></span> <span class="math display">\[ y_{n+1} = y_n + \Delta~\frac{s_1 + s_2}{2}.\]</span></p>
<p>This method is called the <em>Midpoint Method</em>, and we can also implement it in OCaml similarly. Let’s compare the performance of Euler and Midpoint in approximating the true result in eq.&nbsp;4:</p>
<div class="highlight">
<pre><code class="language-ocaml">let f x y = 2. *. x *. y +. x
let f' x = 0.5 *. (Maths.exp (x *. x) -. 1.)

let euler step target = 
    let x = ref 0. in
    let y = ref 0. in
    while !x &lt;= target do 
        y := !y +. step *. (f !x !y);
        x := !x +. step
    done;
    !y

let midpoint step target = 
    let x = ref 0. in
    let y = ref 0. in
    while !x &lt;= target do 
        let s1 = f !x !y in 
        let s2 = f (!x +. step /. 2.) (!y +. step /. 2. *. s1) in 
        y := !y +. step *. (s1 +. s2) /. 2.;
        x := !x +. step
    done;
    !y

let _ = 
    let target = 2.6 in 
    let h = Plot.create "plot_rk01.png" in 
    Plot.(plot_fun ~h ~spec:[ RGB (66,133,244); LineStyle 1; LineWidth 2.; Marker "*" ] f' 2. target);
    Plot.(plot_fun ~h ~spec:[ RGB (219,68,55); LineStyle 2; LineWidth 2.; Marker "+" ] (euler 0.01) 2. target);
    Plot.(plot_fun ~h ~spec:[ RGB (219,68,55); LineStyle 2; LineWidth 2.; Marker "." ] (euler 0.001) 2. target);
    Plot.(plot_fun ~h ~spec:[ RGB (244,180,0); LineStyle 3; LineWidth 2.; Marker "+" ] (midpoint 0.01) 2. target);
    Plot.(plot_fun ~h ~spec:[ RGB (244,180,0); LineStyle 3; LineWidth 2.; Marker "." ] (midpoint 0.001) 2. target);
    Plot.(legend_on h ~position:NorthWest [|"Close-Form Solution"; "Euler (step = 0.01)"; 
        "Euler (step = 0.001)"; "Midpoint (step = 0.01)"; "Midpoint (step = 0.001)"|]);
    Plot.output h</code></pre>
</div>
<p>Let’s see the result.</p>
<figure>
<img alt="" style="width:70.0%" title="plot_rk01" src="images/diffequation/plot_rk01.png"><figcaption>Comparing the accuracy of Euler method and Midpoint method in approximating solution to ODE</figcaption>
</figure>
<p>We can see that the choice of step size indeed matters to the precision. We use 0.01 and 0.001 for step size in the test, and for both cases the midpoint method outperforms the simple Euler method.</p>
<p>Should we stop now? Do we find a perfect solution in midpoint method? Surely no! We can follow the existing trend and add more intermediate stages in the update sequence. For example, we can do this:</p>
<p><span class="math display">\[ s_1 = f(x_n, y_n),\]</span> <span class="math display">\[ s_2 = f(x_n + \Delta~/2, y_n + s_1~\Delta~/2),\]</span> <span id="eq:diffequation:rk4"><span class="math display">\[ s_3 = f(x_n + \Delta~/2, y_n + s_2~\Delta~/2),\qquad(6)\]</span></span> <span class="math display">\[ s_4 = f(x_n + \Delta, y_n + s_3~\Delta),\]</span> <span class="math display">\[ y_{n+1} = y_n + \Delta~\frac{s_1 + 2s_2+2s_3+s_4}{6}.\]</span></p>
<p>Here in each iteration four intermediate steps are computed, once at the initial point, once at the end, and twice at the midpoints. This method often more accurate than the midpoint method.</p>
<p>We won’t keep going on but you have seen the pattern. These seemingly mystical parameters are related to the term in Taylor series expansions. In the previous methods, e.g.&nbsp;Euler method, every time you update <span class="math inline">\(y_n\)</span> to <span class="math inline">\(y_{n+1}\)</span>, an error is introduced into the approximation. The <em>order</em> of a method is the exponent of the smallest power of <span class="math inline">\(\Delta\)</span> that cannot be matched. All these methods are called <em>Runge-Kutta Method</em>. It’s basic idea is to remove the errors order by order, using the correct set of coefficients. A higher order of error indicates smaller error.</p>
<p>The Euler is the most basic form of Runge-Kutta method, and the Midpoint is also called the second-order Runge-Kutta Method (rk2). What eq.&nbsp;6 shows is a fourth-order Runge-Kutta method (rk4). It is the most often used RK method and works surprisingly well in many cases, and it is often a good choice especially when computing <span class="math inline">\(f\)</span> is not expensive.</p>
<p>However, as powerful as it may be, the classical <code>rk4</code> is still a native implementation, and a modern ODE solvers, though largely follows the same idea, adds more “ingredients”. For example, the step size should be adaptively updated instead of being const in our example. Also, you may have seen solvers with names such as <code>ode45</code> in MATLAB, and in their implementation, it means that this solver gets its error estimate at each step by comparing the 4th order solution and 5th order solution and then decide the direction.</p>
<p>Besides, other methods also exists. For example, the Bulirsch-Stoer method is known to be both accurate and and efficient computation-wise. Discussion of these advanced numerical methods and techniques are beyond this book. Please refer to <span data-cites="press2007numerical" class="citation">(Press et al. 2007)</span> for more information.</p>
</section>
<section class="level3" id="owl-ode">
<h3>Owl-ODE</h3>
<p>Now it’s finally the time we use some tools.</p>
<p>A general introduction of Owl-ODE. Its functionality and limit.</p>
<p>The methods we have introduced are all included.</p>
<p>Install</p>
<p>TODO: how to use ODE</p>
<p>One simple example</p>
</section>
<section class="level3" id="choose-ode-solvers">
<h3>Choose ODE solvers</h3>
<p>Question: “why cannot I just use a ‘best’ solver for all the questions?”</p>
<p>Introduce various solvers in Owl-ODE with examples to show their pros and cons.</p>
</section>
</section>
<section class="level2" id="solvers-in-action">
<h2>Solvers in Action</h2>
<p>Examples. A LOT of examples.</p>
<p>Explain stiff vs.&nbsp;non-Stiff</p>
<section class="level3" id="solve-stiff-odes">
<h3>Solve Stiff ODEs</h3>
<p>For some ODE problems, the step size taken by the solver is forced down to an unreasonably small level in comparison to the interval of integration, even in a region where the solution curve is smooth. These step sizes can be so small that traversing a short time interval might require millions of evaluations. This can lead to the solver failing the integration, but even if it succeeds it will take a very long time to do so. Equations that cause this behaviour in ODE solvers are said to be stiff. (Copy alert)</p>
<p>REFER: matlab doc</p>
</section>
<section class="level3" id="solve-non-stiff-odes">
<h3>Solve Non-stiff ODEs</h3>
<p>REFER: matlab doc</p>
</section>
</section>
<section class="level2" id="exercise">
<h2>Exercise</h2>
<ol type="1">
<li>Implement <code>rk4</code> manually and apply to the same problem to compare it’s effect.</li>
</ol>
</section>
<section class="level2 unnumbered" id="references">
<h2 class="unnumbered">References</h2>
<div role="doc-bibliography" class="references hanging-indent" id="refs">
<div id="ref-press2007numerical">
<p>Press, William H, Saul A Teukolsky, William T Vetterling, and Brian P Flannery. 2007. <em>Numerical Recipes 3rd Edition: The Art of Scientific Computing</em>. Cambridge university press.</p>
</div>
</div>
</section>
</section>
</article></div><a href="signal.html" class="next-chapter"><div class="content"><h1><small>Next: Chapter 10</small>Signal Processing</h1></div></a><footer><div class="content"><ul><li><a href="http://ocaml.xyz">ocaml.xyz</a></li><li><a href="https://github.com/ryanrhymes">GitHub</a></li></ul><p>Copyright 2017-2020 Liang Wang.</p></div></footer><script src="js/jquery.min.js"></script><script src="js/min/app-min.js"></script></body></html>