<html style="" lang="en" class="js flexbox fontface"><head><meta charset="utf-8"><meta content="width=device-width, initial-scale=1.0" name="viewport"><title>Optimisation - OCaml Scientific Computing</title><link href="css/app.css" rel="stylesheet"><link href="css/prism.css" rel="stylesheet"><script src="js/min/modernizr-min.js"></script><script src="js/prism.js"></script><script src="https://use.typekit.net/gfj8wez.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>try{Typekit.load();}catch(e){}</script></head><body><div class="title-bar"><div class="title"><h1>OCaml Scientific Computing</h1><h5>1<sup>st</sup> Edition (in progress)</h5><nav><a href="index.html">Home</a><a href="toc.html">Table of Contents</a><a href="faqs.html">FAQs</a><a href="install.html">Install</a><a href="https://ocaml.xyz/package/">API Docs</a></nav></div></div><div class="wrap"><div class="left-column"><a class="to-chapter" href="toc.html"><small>Back</small><h5>Table of Contents</h5></a></div><article class="main-body"><section class="level1" id="optimisation">
<h1>Optimisation</h1>
<p>(The basic idea of this chapter: give a general introduction of this topic regardless of Owl; when Owl has corresponding function, we provide a simple example.)</p>
<section class="level2" id="introduction">
<h2>Introduction</h2>
<p>Mathematical optimisation deals with the problem of finding numerically minimums, maximums (or zeros) of a function. An optimisation problem has the form:</p>
<p><span class="math display">\[\textrm{minimise} f_0(\mathbf{x}),\]</span> <span id="eq:optimisation:def"><span class="math display">\[\textrm{subject to} f_i(\mathbf{x}) \leq b_i, i = 1, 2, \ldots, m. \qquad(1)\]</span></span></p>
<p>Here <span class="math inline">\(\mathbf{x}\)</span> is a vector that contains all the <em>optimisation variable</em>: <span class="math inline">\(\mathbf{x} = [x_0, x_1, ... x_n]\)</span>. Function <span class="math inline">\(f_0 : \mathbf{R}^n \rightarrow \mathbf{R}\)</span> is the optimisation target, and is called an <em>objective function</em>, or <em>cost function</em>. A optimisation problem could be bounded by zero or more <em>constraints</em>. <span class="math inline">\(f_i : \mathbf{R}^n \rightarrow \mathbf{R}\)</span> in a constraint is called a <em>constraint function</em>, which are bounded by the <span class="math inline">\(b_i\)</span>’s. The target is to find the optimal variable values <span class="math inline">\(\mathbf{x}^{*}\)</span> so that <span class="math inline">\(f_0\)</span> can take on a maximum or minimum value.</p>
<p>A optimisation problem formalises the idea “maximum benefit/minimise cost with given constraint”, which is a widely applicable topic in many real world problems: scheduling computation/network resources, optimisation of investment portfolio, fitting math model based on observed data, logistics, aero engineering, competitive games… Optimisation has already been applied in many areas.</p>
<p>In eq.&nbsp;1, if for all the objective function and constraint function, we have:</p>
<p><span id="eq:optimisation:linear"><span class="math display">\[ f_i(\alpha~x+\beta~y) = \alpha~f_i(x) + \beta~f_i(y),\qquad(2)\]</span></span></p>
<p>the optimisation problem is then called <em>linear optimisation</em>. It is an important class of optimisation problems. If we change the “<span class="math inline">\(=\)</span>” to “<span class="math inline">\(\leq\)</span>” in eq.&nbsp;2 make all the functions to be <em>convex</em>, and the problem then becomes <em>convex optimisation</em>, which can be seen as a generalised linear optimisation.</p>
<p>Linear optimisation is important because non-negativity is a usual constraint on real world quantities, and that people are often interested in additive bounds. Besides, many problems can be approximated by a linear model. Though still limited by actual problem size, the solution of most linear optimisation problems are already known and provided by off-the-shelf software tools. The text book <span data-cites="boyd2004convex" class="citation">(Boyd and Vandenberghe 2004)</span> focus exclusively on the topic of convex optimisation.</p>
<p>Compare to linear optimisation, finding solutions to <em>non-linear optimisation</em> problems are still very challenging. Finding a <em>global</em> solution that maximise or minimise the non-linear objective function can be quite time-consuming, even for only a small set of variables. Therefore, global optimisation of a non-linear problem is normally only used when absolutely necessary. For example, if a system pressure test is modelled as an optimisation problem, given a small number of variants in the system, and a global extreme value has to find to test if the system is robust enough. Otherwise, a <em>local</em> maximum or minimum is normally used instead as an approximation. In most engineering applications, a local extreme value is good enough. Though optimisation cannot promise a true extremism, and is easily affected by algorithm parameters and initial guess in iterative algorithms, as a trade-off, local optimisation is much faster and thus still widely used.</p>
<p>Looking back at eq.&nbsp;1, if we remove the constraints, then it becomes an <em>unconstrained optimisation</em> problem. If <span class="math inline">\(f\)</span> is convex and differentiable, this problem can be seen as finding the root of the derivative of <span class="math inline">\(f\)</span> so that <span class="math inline">\(f'(x^*) = 0\)</span>. As for the constrained version, we have introduced the linear programming where all the functions are linear. There are also other types of optimisations such as quadratic programming, semi-definite programming, etc. One subset of constrained optimisation, the <em>equality constrained optimisation</em> where all the constraints are expressed in the form of equality <span class="math inline">\(Ax=b\)</span>. This set of problem can be simplified into the corresponding unconstrained problems.</p>
<p>You can see that the topic of optimisation covers a wide range of topics and we can only give a very brief introduction here. In this chapter, we mostly cover the unconstrained and local optimisation. We will cover the other more advanced content briefly in the end of this chapter, and refer readers to classic books such as <span data-cites="boyd2004convex" class="citation">(Boyd and Vandenberghe 2004)</span> and <span data-cites="fletcher2013practical" class="citation">(Fletcher 2013)</span> for more information.</p>
<p>(NOTE: if we decide to add linear programming later, we can extend the constrained)</p>
<p>(NOTE: We need a lot of illustrations to show the gradient process)</p>
</section>
<section class="level2" id="numerical-differentiation-vs.-algorithm-differentiation">
<h2>Numerical Differentiation VS. Algorithm Differentiation</h2>
<p>The derivative/gradient will be used extensively in solving optimisation problems. Therefore, it would do no harm to start this chapter with understanding the difference of the two ways to compute derivatives: <em>algorithm differentiation</em> and <em>numerical differentiation</em>.</p>
<p>We have talked about algorithm differentiation* in detail in the previous chapter. What is this numerical differentiation then? It’s actually simple according to the definition of derivative itself:</p>
<p><span id="eq:optimisation:numdiff"><span class="math display">\[f'(x) = \lim_{\delta~\to~0}\frac{f(x+\delta) - f(x)}{\delta}.\qquad(3)\]</span></span></p>
<p>This method is pretty easy to follow: evaluate the given <span class="math inline">\(f\)</span> at point <span class="math inline">\(x\)</span>, and then choose a suitable small amount <span class="math inline">\(\delta\)</span>, add it to the original <span class="math inline">\(x\)</span> and then re-evaluate the function. Then the derivative can be calculated using eq.&nbsp;3. We can implement this method easily using OCaml:</p>
<div class="highlight">
<pre><code class="language-ocaml">let _eps = 0.00001

let diff f x = (f (x +. _eps) -. f (x -. _eps)) *. _ep2</code></pre>
</div>
<p>We can apply it to a simple case:</p>
<div class="highlight">
<pre><code class="language-clike">CODE</code></pre>
</div>
<p>Looks good.</p>
<p>Owl has provided numerical differentiation. It’s close to the interface of that of Algodiff:</p>
<div class="highlight">
<pre><code class="language-clike">val diff : (elt -&gt; elt) -&gt; elt -&gt; elt
(** derivative of ``f : scalar -&gt; scalar``. *)

val diff2 : (elt -&gt; elt) -&gt; elt -&gt; elt
(** second order derivative of ``f : float -&gt; float``. *)

val grad : (arr -&gt; elt) -&gt; arr -&gt; arr
(** gradient of ``f : vector -&gt; scalar``. *)

val jacobian : (arr -&gt; arr) -&gt; arr -&gt; arr
(** jacobian of ``f : vector -&gt; vector``. *)

val jacobianT : (arr -&gt; arr) -&gt; arr -&gt; arr
(** transposed jacobian of ``f : vector -&gt; vector``. *)</code></pre>
</div>
<p>Looks nice, much easier than Algodiff’s approach, right?</p>
<p>No.&nbsp;</p>
<p>There are two source of errors: truncating error (explain) and roundoff error (explain). You must be very careful and apply some numerical techniques. While Algodiff guarantees a true derivative value without loss of accuracy. you can see the difference in this example:</p>
<div class="highlight">
<pre><code class="language-clike">CODE (how to show the difference)?</code></pre>
</div>
<p>For the rest of this chapter, we prefer to use the algorithm differentiation to compute gradient/derivatives when required, but of course you can also use the numerical differentiation.</p>
</section>
<section class="level2" id="root-finding">
<h2>Root Finding</h2>
<p>Root Finding is not exactly optimisation, however, the two topics are closely related. Both need to find target on a function iteratively.</p>
<p>Understanding the method used in root finding is very helpful for understanding the method in optimisation.</p>
<section class="level3" id="newton-secant-and-iqi">
<h3>Newton, Secant, and IQI</h3>
<p>First, bisect method.</p>
<p>In Newton, we use algodiff to compute the derivative; actually we can use the owl example here.</p>
<p>If derivative is not available, Secant replaces the derivative evaluation in Newton.</p>
<p>In Secant, we use two points to get to the next one; IQI, we use three.</p>
</section>
<section class="level3" id="brents-method">
<h3>Brent’s Method</h3>
<p>It’s a combination of those three. Generally considered the best of the root-finding routines.</p>
<p>We implement it in Owl (put some Code here..?)</p>
<p>It is also what we use in the examples in “Math” chapter.</p>
</section>
</section>
<section class="level2" id="scalar-function-optimisation">
<h2>Scalar Function Optimisation</h2>
<p>Now after we understand the root-finding, let’s look at optimisation problem. Let’s start with the simple case that only one variable in the objective function.</p>
<section class="level3" id="use-derivative">
<h3>Use Derivative</h3>
<p>Extreme value can be found where the derivatives equals 0:</p>
<p><span class="math display">\[f'(x) = 0\]</span></p>
<p>Let’s use algodiff to do that.</p>
<p>A simple example.</p>
</section>
<section class="level3" id="golden-section-search">
<h3>Golden Section Search</h3>
<p>But what if derivative is not available?</p>
<p>It’s an optimisation method that does NOT require computing derivative.</p>
<p>Basic idea: in root-finding, you move two number to locate the zero point. Here you need three. And Golden search is an efficient way to do that.</p>
<p>If your function has a discontinuous first or second derivative, then use this.</p>
</section>
</section>
<section class="level2" id="multivariate-function-optimisation">
<h2>Multivariate Function Optimisation</h2>
<p>When things become more complex…</p>
<section class="level3" id="nelder-mead-simplex-method">
<h3>Nelder-Mead Simplex Method</h3>
<p>Gradient is the popular way, but first, let’s briefly look at the method that does not require gradient.</p>
<p>Also mention Powell’s Method if we have space left</p>
</section>
<section class="level3" id="gradient-descent-methods">
<h3>Gradient Descent Methods</h3>
<p>Find the zero point: Gradient Descent.</p>
</section>
<section class="level3" id="conjugate-gradient-method">
<h3>Conjugate Gradient Method</h3>
</section>
<section class="level3" id="quasi-newton-methods">
<h3>Quasi-Newton Methods</h3>
<p>BFGS</p>
</section>
</section>
<section class="level2" id="global-optimisation-and-constrained-optimisation">
<h2>Global Optimisation and Constrained Optimisation</h2>
<p>So far we have talked about unconstrained optimisation, mostly to find local optimal. In the rest of this chapter we will give a very very brief introduction to global optimisation and constrained optimisation</p>
<p>The basic idea of global optimisation.</p>
<p>The type of problems covered constrained optimisation; applications. Currently can they be solved and how to solve them with existing tools.</p>
<div role="doc-bibliography" class="references hanging-indent" id="refs">
<div id="ref-boyd2004convex">
<p>Boyd, Stephen, and Lieven Vandenberghe. 2004. <em>Convex Optimization</em>. Cambridge university press.</p>
</div>
<div id="ref-fletcher2013practical">
<p>Fletcher, Roger. 2013. <em>Practical Methods of Optimization</em>. John Wiley &amp; Sons.</p>
</div>
</div>
</section>
</section>
</article></div><a href="regression.html" class="next-chapter"><div class="content"><h1><small>Next: Chapter 13</small>Regression</h1></div></a><footer><div class="content"><ul><li><a href="http://ocaml.xyz">ocaml.xyz</a></li><li><a href="https://github.com/ryanrhymes">GitHub</a></li></ul><p>Copyright 2017-2020 Liang Wang.</p></div></footer><script src="js/jquery.min.js"></script><script src="js/min/app-min.js"></script></body></html>