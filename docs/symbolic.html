<html style="" lang="en" class="js flexbox fontface"><head><meta charset="utf-8"><meta content="width=device-width, initial-scale=1.0" name="viewport"><title>Symbolic Representation - OCaml Scientific Computing</title><link href="css/app.css" rel="stylesheet"><link href="css/prism.css" rel="stylesheet"><script src="js/min/modernizr-min.js"></script><script src="js/prism.js"></script><script src="https://use.typekit.net/gfj8wez.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>try{Typekit.load();}catch(e){}</script></head><body><div class="title-bar"><div class="title"><h1>OCaml Scientific Computing</h1><h5>1<sup>st</sup> Edition (in progress)</h5><nav><a href="index.html">Home</a><a href="toc.html">Table of Contents</a><a href="faqs.html">FAQs</a><a href="install.html">Install</a><a href="https://ocaml.xyz/package/">API Docs</a></nav></div></div><div class="wrap"><div class="left-column"><a class="to-chapter" href="toc.html"><small>Back</small><h5>Table of Contents</h5></a></div><article class="main-body"><section class="level1" id="symbolic-representation">
<h1>Symbolic Representation</h1>
<section class="level2" id="introduction">
<h2>Introduction</h2>
<p>The development of <code>owl_symbolic</code> library is motivated by multiple factors. For one thing, scientific computation can be considered as consisting of two broad categories: numerical computation, and symbolic computation. Owl has achieved a solid foundation in the former, but as yet to support the latter one, which is heavily utilised in a lot of fields. For another, with the development of neural network compilers such as <a href="https://tvm.apache.org/">TVM</a>, it is a growing trend that the definition of computation can be separated out, and the low level compilers to deal with optimisation and code generation etc. to pursue best computation performance. Besides, tasks such as visualising a computation also require some form or intermediate representation (IR). Owl has already provided a computation graph layer to separate the definition and execution of computation to improve the performance, but it’s not an IR layer to perform these different tasks as mentioned before. Towards this end, we begin to develop an intermediate symbolic representation of computations and facilitate various tasks based on this symbol representation.</p>
<p>One thing to note is that do not mistake our symbolic representation as the classic symbolic computation (or Computer Algebra System) that manipulate mathematical expressions in a symbolic way, which is similar to the traditional manual computations. It is indeed one of our core motivation to pursue the symbolic computation with Owl. Currently we provide a symbolic representation layer as the first step towards that target. More discussion will be added in future versions with the development with the support of symbolic math in Owl.</p>
</section>
<section class="level2" id="design">
<h2>Design</h2>
<p><code>owl_symbolic</code> is divided into two parts: the core symbolic representation that constructs a symbolic graph, and various engines that perform different task based on the graph. The architecture design of this system is shown in fig.&nbsp;1.</p>
<figure>
<img alt="" style="width:90.0%" id="fig:symbolic:architecture" title="architecture" src="images/symbolic/architecture.png"><figcaption>Figure 1: Architecture of the symbolic system</figcaption>
</figure>
<p>The core abstraction is a independent symbolic representation layer. Based on this layer, we have various engines that can be translated to and from this symbolic representation. Currently we support three engines: the ONNX binary format, the computation graph in Owl, and the LaTeX string. The CAS engine is currently still an on-going research project, and we envision that, once finished, this engine can be used to pre-process a symbolic representation so that it as an simplified canonical form before being processed by other engines.</p>
<section class="level3" id="core-abstraction">
<h3>Core abstraction</h3>
<p>The core part is designed to be minimal and contains only necessary information. Currently it has already covered many common computation types, such as math operations, tensor manipulations, neural network specific operations such as convolution, pooling etc. Each symbol in the symbolic graph performs a certain operation. Input to a symbolic graph can be constants such as integer, float number, complex number, and tensor. The input can also be variables with certain shapes. An empty shape indicates a scalar value. The users can then provide values to the variable after the symbolic graph is constructed.</p>
<p>The symbolic representation is defined mainly as array of <code>symbol</code>. Each <code>symbol</code> is a graph node that has an attribution of type <code>Owl_symbolic_symbol.t</code>. It means that we can traverse through the whole graph by starting with one <code>symbol</code>. Besides symbols, the <code>name</code> field is the graph name, and <code>node_names</code> contains all the nodes’ name contained in this graph.</p>
<div class="highlight">
<pre><code class="language-ocaml">type symbol = Owl_symbolic_symbol.t Owl_graph.node

type t =
  { mutable sym_nodes : symbol array
  ; mutable name : string
  ; mutable node_names : string array
  }</code></pre>
</div>
<p>Let’s look at <code>Owl_symbolic_symbol.t</code>. It defines all the operations contained in the symbolic representation:</p>
<div class="highlight">
<pre><code class="language-clike">type t =
  | NOOP
  | Int                   of Int.t
  | Complex               of Complex.t
  | Float                 of Float.t
  | Tensor                of Tensor.t
  | Variable              of Variable.t
  | RandomUniform         of RandomUniform.t
  | Sin                   of Sin.t
  | Cos                   of Cos.t
  | Exp                   of Exp.t
  | ReduceSum             of ReduceSum.t
  | Reshape               of Reshape.t
  | Conv                  of Conv.t
  ....</code></pre>
</div>
<p>There are totally about 150 operations included in our symbolic representation. Each operation is implemented as a module. These modules share common attributes such as name, input operation names, output shapes, and then each module contains zero or more attributes of itself. For example, the <code>Sin</code> operation module is implemented as:</p>
<div class="highlight">
<pre><code class="language-clike">module Sin = struct
  type t =
    { mutable name : string
    ; mutable input : string array
    ; mutable out_shape : int array option array
    }

  let op_type = "Sin"

  let create ?name x_name =
    let input = [| x_name |] in
    let name = Owl_symbolic_utils.node_name ?name op_type in
    { name; input; out_shape = [| None |] }
end</code></pre>
</div>
<p>The module provides properties such as <code>op_type</code> and functions such as <code>create</code> that returns object of type <code>Sin.t</code>. The <code>name</code>, <code>input</code> and <code>out_shape</code> are common attributes in the operation modules.</p>
<p>In implementing the supported operations, we follow the category used in ONNX. These operations can be generally divided into these different groups:</p>
<ul>
<li>Generators: operations that generate data, taking no input. For example, the <code>Int</code>, <code>Float</code>, <code>Tensor</code>, <code>Variable</code>, etc.</li>
<li>Logical: logical operations such as <code>Xor</code>.</li>
<li>Math: mathematical operations. This group of operations makes a large part of the total operations supported.</li>
<li>Neural Network: neural network related operations such as convolution and pooling.</li>
<li>Object detection: also used in neural network, but the operations that are closely related with object detection applications, including <code>RoiAlign</code> and <code>NonMaxSuppression</code>.</li>
<li>Reduction: reduction (or folding) math operations such as sum reduce.</li>
<li>RNN: Recurrent neural network related operations such as LTSM.</li>
<li>Tensor: Normal tensor operations, like the ones that are included in the Ndarray module, such as <code>concat</code>, <code>reshape</code>, etc.</li>
<li>Sequence: take multiple tensor as one single object called <code>sequence</code>, and there are different corresponding functions on the sequence type data, such as <code>SequenceInsert</code>, <code>SequenceLength</code> etc.</li>
</ul>
<p>Based on these operation modules, we provide several functions on the <code>Owl_symbolic_symbol.t</code> type:</p>
<ul>
<li><code>name</code>: get the name of operation</li>
<li><code>op_type</code>: get the operation type string</li>
<li><code>input</code>: get the input nodes name of an operation</li>
<li><code>set_input</code>: update the input nodes name</li>
<li><code>output</code>: get the output nodes name</li>
<li><code>set_output</code>: update the output nodes name</li>
</ul>
<p>There are also some functions that only apply to certain types of operations. The generator type of operations all need to specify the type of data it supports. Therefore, we use <code>dtype</code> function to check their data types. Another example is the <code>output</code> property. For most of the operation, it has only one output, and therefore its name is its output name. However, for operations such as <code>MaxPool</code> that contains multiple output, we need another function: <code>output</code>.</p>
<p>All these operations are invisible to users. What the users really uses is the <em>operators</em>. To build a graph, we first need to build the required attributes into an operation, and then put it into a graph node. This is what an operator does. Take the <code>sin</code> operator as an example:</p>
<div class="highlight">
<pre><code class="language-clike">let sin ?name x =
  let xn = Owl_symbolic_graph.name x in
  let s = Owl_symbolic_ops_math.Sin.create ?name xn in
  make_node (Owl_symbolic_symbol.Sin s) [| x |]</code></pre>
</div>
<p>Here the <code>sin</code> operator takes its parent node <code>x</code> as input, get its name as input property, and create a symbol node with the function <code>make_node</code>. This function takes an operation and an array of parent symbols, and then creates one symbol as return. What it does is mainly creating a child node using the given operation as node attribution, updating the child’s input and output shape, and then connecting the child with parents before returning the child node. The connection is on both direction:</p>
<div class="highlight">
<pre><code class="language-clike">connect_ancestors parents [| child |];
let uniq_parents = Owl_utils_array.unique parents in
Array.iter (fun parent -&gt; connect_descendants [| parent |] [| child |]) uniq_parents</code></pre>
</div>
<p>Most of the operators are straightforward to implement, but some of them returns multiple symbols as return. EXPLAIN.</p>
<p>Currently we adopt a global naming scheme, which is to add an incremental index number after each node’s type. For example, if we have an <code>Add</code> symbol, a <code>Div</code> symbol, and then another <code>Add</code> symbol in a graph, then each node will be named <code>add_0</code>, <code>div_1</code>, and <code>add_1</code>. One exception is the variable, where a user has to explicitly name when create a variable. Of course, users can also optionally any node in the graph, but the system will check to make sure the name of each node is unique.</p>
One task the symbolic core needs to perform is shape checking and shape inferencing. The type supported by <code>owl_symbolic</code> is listed as follows:
<div class="highlight">
<pre><code class="language-ocaml">type elem_type =
  | SNT_Noop
  | SNT_Float
  | SNT_Double
  | SNT_Complex32
  | SNT_Complex64
  | SNT_Bool
  | SNT_String
  | SNT_Int8
  | SNT_Int16
  | SNT_Int32
  | SNT_Int64
  | SNT_Uint8
  | SNT_Uint16
  | SNT_Uint32
  | SNT_Uint64
  | SNT_Float16
  | SNT_SEQ of elem_type</code></pre>
</div>
<p>This list of types covers most number and non-number types. <code>SNT_SEQ</code> means the type a list of the basic elements as inputs/outputs. Type inference happens every time a user uses an operation to construct a symbolic node and connect it with previous nodes. It is assumed that the parents of the current node are already known. The inferenced output shape is saved in each node. In certain rare cases, the output shape depends on the runtime content of input nodes, not just the shapes of input nodes and attributions of the currents node. In that case, the output shapes is set to <code>None</code>. Once the input shapes contain <code>None</code>, the shape inference results hereafter will all be <code>None</code>, which means the output shapes cannot be decided at compile time.</p>
<p>The core part provides symbolic operations as user interface. Each operation constructs a <code>symbol</code> and creates a <code>symbol Owl_graph.node</code> as output. Some symbol generates multiple outputs. In that case, an operation returns not a node, but a tuple or, when output numbers are uncertain, an array of nodes.</p>
</section>
<section class="level3" id="engines">
<h3>Engines</h3>
<p>Based on this simple core abstraction, we use different <em>engines</em> to provide functionalities: converting to and from other computation expression formats, print out to human-readable format, graph optimisation, etc. As we have said, the core part is kept minimal. If the engines require information other than what the core provides, each symbol has an <code>attr</code> property as extension point.</p>
<p>All engines must follow the signature below:</p>
<div class="highlight">
<pre><code class="language-ocaml">type t

val of_symbolic : Owl_symbolic_graph.t -&gt; t
val to_symbolic : t -&gt; Owl_symbolic_graph.t
val save : t -&gt; string -&gt; unit
val load : string -&gt; t</code></pre>
</div>
<p>It means that, each engine has its own core type <code>t</code>, be it a string or another format of graph, and it needs to convert <code>t</code> to and from the core symbolic graph type, or save/load a type <code>t</code> data structure to file. An engine can also contain extra functions besides these four.</p>
<p>Now that we have explained the design of <code>owl_symbolic</code>, let’s look at the details of some engines in the next few sections.</p>
</section>
</section>
<section class="level2" id="onnx-engine">
<h2>ONNX Engine</h2>
<p>The ONNX Engine is the current focus of development in <code>owl_symbolic</code>. <a href="https://onnx.ai">ONNX</a> is a widely adopted open neural network exchange format. A neural network model defined in ONNX can be, via suitable converters, can be run on different frameworks and thus hardware accelerators. The main target of ONNX is to promote the interchangeability of neural network and machine learning models, but it is worthy of noting that the standard covers a lot of basic operations in scientific computation, such as power, logarithms, trigonometric functions, etc. Therefore, ONNX engines serves as a good starting point for its coverage of operations.</p>
<p>Taking a symbolic graph as input, how would then the ONNX engine produce ONNX model? We use the <a href="https://github.com/mransan/ocaml-protoc">ocaml-protoc</a>, a protobuf compiler for OCaml, as the tool. The ONNX specification is defined in an <a href="https://github.com/onnx/onnx/blob/master/onnx/onnx.proto">onnx.proto</a> file, and the <code>ocaml-protoc</code> can compile this protobuf files into OCaml types along with serialisation functions for a variety of encodings.</p>
<p>For example, the toplevel message type in onnx.proto is <code>MessageProto</code>, defined as follows:</p>
<div class="highlight">
<pre><code class="language-proto">message ModelProto {
  optional int64 ir_version = 1;
  repeated OperatorSetIdProto opset_import = 8;
  optional string producer_name = 2;
  optional string producer_version = 3;
  optional string domain = 4;
  optional int64 model_version = 5;
  optional string doc_string = 6;
  optional GraphProto graph = 7;
  repeated StringStringEntryProto metadata_props = 14;
};</code></pre>
</div>
<p>And the generated OCaml types and serialisation function are:</p>
<div class="highlight">
<pre><code class="language-ocaml">open Owl_symbolic_specs.PT

type model_proto =
  { ir_version : int64 option
  ; opset_import : operator_set_id_proto list
  ; producer_name : string option
  ; producer_version : string option
  ; domain : string option
  ; model_version : int64 option
  ; doc_string : string option
  ; graph : graph_proto option
  ; metadata_props : string_string_entry_proto list
  }

val encode_model_proto : Onnx_types.model_proto -&gt; Pbrt.Encoder.t -&gt; unit</code></pre>
</div>
<p>Besides the meta information such as model version and IR version etc., a model is mainly a graph, which includes input/output information and an array of nodes. A node specifies operator type, input and output node name, and its own attributions, such as the <code>axis</code> attribution in reduction operations.</p>
<p>Therefore, all we need is to build up a <code>model_proto</code> data structure gradually from attributions to nodes, graph and model. It can then be serialised using <code>encode_model_proto</code> to generate a protobuf format file, and that is the ONNX model we want.</p>
<p>Besides building up the model, one other task to be performed in the engine is type checking and type inferencing. The <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">operator documentation</a> lists the type constraints of each operator. For example, the sine function can only accept input of float or double number types, and generate the same type of input as that of input. Each type of operator has its own rules of type checking and inferencing. Starting from input nodes, which must contain specific type information, this chain if inferencing can thus verify the whole computation meets the type constraints for each node, and then yield the final output types of the whole graph. The reason that type checking is performed at the engine side instead of the core is that each engine may have different type constraints and type inferencing rules for the operators.</p>
<section class="level3" id="example-1-basic-operations">
<h3>Example 1: Basic operations</h3>
<p>Let’s look at a simple example.</p>
<div class="highlight">
<pre><code class="language-ocaml">open Owl_symbolic
open Op
open Infix

let x = variable "X"
let y = variable "Y"
let z = exp ((sin x ** float 2.) + (cos x ** float 2.)) + (float 10. * (y ** float 2.))
let g = SymGraph.make_graph [| z |] "sym_graph"
let m = ONNX_Engine.of_symbolic g
let _ = ONNX_Engine.save m "test.onnx"</code></pre>
</div>
<p>After including necessary library component, the first three line of code creates a symbolic representation <code>z</code> using the symbolic operators such as <code>sin</code>, <code>pow</code> and <code>float</code>. The <code>x</code> and <code>y</code> are variables that accept user input. It is then used to create a symbolic graph. This step mainly checks if there is any duplication of node names. Then the <code>of_symbolic</code> function in ONNX engine takes the symbolic graph as input, and generates a <code>model_proto</code> data structure, which can be further saved as a model named <code>test.onnx</code>.</p>
<p>To use this ONNX model we could use any framework that supports ONNX. Here we use the Python-based <a href="https://github.com/microsoft/onnxruntime">ONNX Runtime</a> as an example. We prepare a simple Python script as follows:</p>
<div class="highlight">
<pre><code class="language-python">import numpy as np
import math
import onnxruntime as rt

sess = rt.InferenceSession("test.onnx")
input_name_x = sess.get_inputs()[0].name
input_name_y = sess.get_inputs()[1].name
x = np.asarray(math.pi, dtype="float32")
y = np.asarray(3., dtype="float32")

pred_onx = sess.run(None, {input_name_x: x, input_name_y: y})[0]
print(pred_onx)</code></pre>
</div>
<p>This script is very simple: it loads the ONNX model we have just created, and then get the two input variables, and assign two values to them in the <code>sess.run</code> command. All the user need to know in advance is that there are two input variables in this ONNX model. Note that we could define not only scalar type input but also tensor type variables in <code>owl_symbolic</code>, and then assign NumPy array to them when evaluating.</p>
</section>
<section class="level3" id="example-2-neural-network">
<h3>Example 2: Neural network</h3>
<p>The main purpose of the ONNX standard is for expressing neural network models, and we have already cover most of the common operations that are required to construct neural networks. However, to construct a neural network model directly from existing <code>owl_symbolic</code> operations requires a lot of details such as input shapes or creating extra nodes. To make things easier for the users, we create neural network layer based on existing symbolic operations. This light-weight layer takes only 180 LoC, and yet it provides a Owl-like clean syntax for the users to construct neural networks. For example, we can construct a MNIST-DNN model:</p>
<div class="highlight">
<pre><code class="language-ocaml">open Owl_symbolic_neural_graph
let nn =
  input [| 100; 3; 32; 32 |]
  |&gt; normalisation
  |&gt; conv2d [| 32; 3; 3; 3 |] [| 1; 1 |]
  |&gt; activation Relu
  |&gt; max_pool2d [| 2; 2 |] [| 2; 2 |] ~padding:VALID
  |&gt; fully_connected 512
  |&gt; activation Relu
  |&gt; fully_connected 10
  |&gt; activation (Softmax 1)
  |&gt; get_network

let _ =
  let onnx_graph = Owl_symbolic_engine_onnx.of_symbolic nn in
  Owl_symbolic_engine_onnx.save onnx_graph "test.onnx"</code></pre>
</div>
<p>Besides this simple DNN, we have also created the complex architectures such as ResNet, InceptionV3, SqueezeNet, etc. They are all adapted from existing Owl DNN models with only minor change. The execution of the generated ONNX model is similar:</p>
<div class="highlight">
<pre><code class="language-python">import numpy as np
import onnxruntime as rt

sess = rt.InferenceSession("test.onnx")
input_name_x = sess.get_inputs()[0].name
input_name_shape = sess.get_inputs()[0].shape
input_x = np.ones(input_name_shape , dtype="float32")
pred_onx = sess.run(None, {input_name_x: input_x})[0]</code></pre>
</div>
<p>For simplicity, we generate a dummy input for the execution/inference phase of this model. Of course, currently in our model the weight data is not trained. Training of a model should be completed on a framework such as TensorFlow. Combining trained weight data into the ONNX model remains to be a future work.</p>
<p>Furthermore, by using tools such as <code>js_of_ocaml</code>, we can convert both examples into JavaScript; executing them can create the ONNX models, which in turn can be executed on the browser using <a href="https://github.com/microsoft/onnxjs">ONNX.js</a> that utilises WebGL. In summary, using ONNX as the intermediate format for exchange computation across platforms enables numerous promising directions.</p>
</section>
</section>
<section class="level2" id="latex-engine">
<h2>LaTeX Engine</h2>
<p>The LaTeX engine takes a symbolic representation as input, and produce LaTeX strings which can then be visualised using different tools. For example, we have built a web UI in this Engine that utilises <a href="https://katex.org/">KaTeX</a>, which renders LaTeX string directly on a browser. Below is an example, where we define an math symbolic graph, convert it into LaTeX string, and show this string on our web UI using the functionality the engine provides.</p>
<div class="highlight">
<pre data-filter-output=">" data-prompt="#" class="command-line"><code class="language-ocaml">open Owl_symbolic;;
open Op;;
open Infix;;
let make_expr0 () =
  let x = variable "x_0" in
  (* construct *)
  let y =
    exp ((sin x ** float 2.) + (cos x ** float 2.))
    + (float 10. * (x ** float 2.))
    + exp (pi () * complex 0. 1.)
  in
  SymGraph.make_graph [| y |] "sym_graph"
;;
&gt;val make_expr0 : unit -&gt; Owl_symbolic_graph.t = &lt;fun&gt;
let () = make_expr0 () 
  |&gt; LaTeX_Engine.of_symbolic 
  |&gt; print_endline
;;
&gt;\exp(\sin(x_0) ^ 2 + \cos(x_0) ^ 2) + 10 \times x_0 ^ 2 + \exp(\pi \times 1.00i)
let () = 
  let exprs = [ make_expr0 () ] in 
  LaTeX_Engine.html ~dot:true ~exprs "example.html"
;;
</code></pre>
</div>
<p>The generated “example.html” webpage is a standalone page that contains all the required scripts. Once opened in a browser, it looks like this:</p>
<figure>
<img alt="" style="width:90.0%" id="fig:symbolic:ui" src="images/symbolic/latex_01.png"><figcaption>Figure 2: UI of LaTeX engine</figcaption>
</figure>
<p>For each expression, the web UI contains its rendered LaTeX form and corresponding computation graph.</p>
</section>
<section class="level2" id="owl-engine">
<h2>Owl Engine</h2>
<p>An Owl Engine enables converting Owl computation graph to or from a symbolic representation. Symbolic graph can thus benefit from the concise syntax and powerful features such as Algorithm Differentiation in Owl.</p>
<p>We can also chain multiple engines together. For example, we can use Owl engine to converge the computation define in Owl to symbolic graph, which can then be converted to ONNX model and get executed on multiple frameworks. Here is such an example. A simple computation graph created by <code>make_graph ()</code> is processed by two chained engines, and generates an ONNX model.</p>
<div class="highlight">
<pre><code class="language-ocaml">open Owl_symbolic
module G = Owl_computation_cpu_engine.Make (Owl_algodiff_primal_ops.S)
module AD = Owl_algodiff_generic.Make (G)
module OWL_Engine = Owl_symbolic_engine_owl.Make (G)

let make_graph () =
  let x = G.ones [| 2; 3 |] |&gt; AD.pack_arr in
  let y = G.var_elt "y" |&gt; AD.pack_elt in
  let z = AD.Maths.(sin x + y) in
  let input = [| AD.unpack_elt y |&gt; G.elt_to_node |] in
  let output = [| AD.unpack_arr z |&gt; G.arr_to_node |] in
  G.make_graph ~input ~output "graph"

let _ =
  let k = make_graph () |&gt; OWL_Engine.to_symbolic |&gt; ONNX_Engine.of_symbolic in
  ONNX_Engine.save k "test.onnx"</code></pre>
</div>
</section>
<section class="level2" id="summary">
<h2>Summary</h2>
</section>
</section>
</article></div><a href="architecture.html" class="next-chapter"><div class="content"><h1><small>Next: Chapter 19</small>Architecture Overview</h1></div></a><footer><div class="content"><ul><li><a href="http://ocaml.xyz">ocaml.xyz</a></li><li><a href="https://github.com/ryanrhymes">GitHub</a></li></ul><p>Copyright 2017-2020 Liang Wang.</p></div></footer><script src="js/jquery.min.js"></script><script src="js/min/app-min.js"></script></body></html>